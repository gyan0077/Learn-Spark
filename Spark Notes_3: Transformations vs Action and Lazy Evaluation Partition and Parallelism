============= 1ï¸âƒ£ Transformations - (They build the plan)
Transformations define what you want to do to the data.
They do not execute immediately.

============= 2ï¸âƒ£ Actions - (They trigger execution)
Actions ask Spark for a result.
When an action is called, Spark executes the whole DAG.

============= 3ï¸âƒ£ Lazy Evaluation (Why Spark waits)
Lazy evaluation means Spark waits until an action before doing any work.
Note: Spark first records transformations, then optimizes, then executes once.

============= Real-life analogy ğŸ³ =============
Transformations = writing a recipe.
Action = turning on the stove.
Lazy evaluation = not cooking until someone orders food.

=============================== Spark Transformations (Lazy â€“ build the plan) =======================================
Transformations define what to do. They donâ€™t execute immediately.

ğŸ”¸ Narrow Transformations: 
-- Each output partition depends on only ONE input partition (NO shuffle)

What spark does:
Partition 1 â†’ Partition 1
Partition 2 â†’ Partition 2
Partition 3 â†’ Partition 3

Data from one partition stays in the same partition.
| -----------------------|-------------------------------------------- |
| Transformation         | What it does                                |
| ---------------------- | ------------------------------------------- |
| `select()`             | Choose columns                              |
| `filter()` / `where()` | Filter rows                                 |
| `withColumn()`         | Add/modify column                           |
| `drop()`               | Remove column                               |
| `map()`                | Row-wise transform                          |
| `flatMap()`            | Map + flatten                               |
| `sample()`             | Sample rows                                 |
| `limit()`              | Limit rows                                  |



ğŸ”¸ Wide Transformations:
-- Each output partition depends on MULTIPLE input partitions (Shuffle happens)

What Spark does: 
Partition 1 â”€â”
Partition 2 â”€â”¼â”€â–º Shuffle â”€â–º New Partitions
Partition 3 â”€â”˜

Data must move across partitions.
| Transformation         | What it does                        |
| ---------------------- | ----------------------------------- |
| `groupBy()`            | Group rows                          |
| `agg()`                | Aggregations                        |
| `join()`               | Combine DataFrames                  |
| `repartition()`        | Change partitions                   |
| `orderBy()` / `sort()` | Sort data                           |
| `cube()` / `rollup()`  | Multi-dim aggregations              |


ğŸ”¹ Spark Actions (Eager â€“ trigger execution)
Actions trigger the execution of the entire DAG.
| Action          | Result               |
| --------------- | -------------------- |
| `show()`        | Display rows         |
| `count()`       | Row count            |
| `collect()`     | Bring data to driver |
| `take(n)`       | First `n` rows       |
| `first()`       | First row            |
| `foreach()`     | Apply function       |
| `write()`       | Save to storage      |
| `saveAsTable()` | Save as table        |
| `reduce()`      | Aggregate values     |


ğŸ”¹ Transformations vs Actions (Quick Recall)
| Aspect       | Transformation | Action          |
| ------------ | -------------- | --------------- |
| Execution    | Lazy           | Immediate       |
| Builds DAG   | âœ…              | âŒ            |
| Triggers job | âŒ              | âœ…            |
| Output       | DataFrame      | Result / Output |


======================== Eager transaformation ==========================
Spark has NO eager transformations.
All Spark transformations are lazy.
Only actions are eager.

========================= What is Fault Tolerance in Spark? =========================
Fault tolerance means Spark can recover from failures (node, executor, task) without restarting the entire job or losing data.

ğŸ”¹ Types of Failures Spark Handles
1ï¸âƒ£ Executor failure (most common)
2ï¸âƒ£ Task failure
3ï¸âƒ£ Node failure
4ï¸âƒ£ Data loss in memory
Spark handles all of these automatically.

ğŸ”¹ How Spark Achieves Fault Tolerance (Key Concepts)
1ï¸âƒ£ DAG Lineage (MOST IMPORTANT)
Spark does NOT replicate data like Hadoop. Instead, it remembers how data was created.
This is called lineage.

2ï¸âƒ£ Task Re-execution:
If a task fails:Spark retries it automatically,Runs the same task on another executor.
Ex:
Executor 2 crashes
â†’ Spark reruns the same task on Executor 5

3ï¸âƒ£ Partition-Based Recovery:
Spark processes data in partitions.
If one partition is lost:
Only that partition is recomputed
Not the entire dataset
ğŸ“Œ This makes recovery fast and efficient.


=========================== ğŸ”‘ Golden Rule (Very Important)  ===========================
If you see Exchange in .explain() â†’ it is a WIDE transformation
No Exchange â†’ Narrow transformation.



==========================  Partitions & Parallelism
1ï¸âƒ£ Partitions â€” How data is split.
A partition is a chunk of data that Spark processes independently.
DataFrames/RDDs are divided into partitions
One task processes one partition

========================== Why partitions matter
They decide how many tasks Spark can run
Too few â†’ underutilized CPUs
Too many â†’ overhead (scheduling, small tasks)

2ï¸âƒ£ Parallelism â€” How much work runs at once
Parallelism is the number of tasks running concurrently.
Parallelism â‰ˆ number of partitions being processed at the same time
Bounded by available cores across executors

========================== Rule of thumb
Aim for 2â€“4Ã— total cores as partitions for CPU-heavy jobs
Example: 8 cores â‡’ ~16â€“32 partitions

3ï¸âƒ£ repartition() â€” Force a new partitioning (shuffle) ğŸš¨
repartition(n) reshuffles data to create exactly n partitions.

========================== What it does
i)    Wide transformation
ii)   Full shuffle
iii)  Useful to increase partitions or rebalance skew

========================== When to use
Before large joins/aggregations to improve parallelism
After reading a small file that has too few partitions

4ï¸âƒ£ coalesce() vs repartition() (must-know)
coalesce(n): reduces partitions without shuffle (narrow)
repartition(n): changes partitions with shuffle (wide)
Example: 
df.coalesce(4)    # fast, no shuffle (reduce only)
df.repartition(4) # shuffle (increase or rebalance)

ğŸ‘: Partitions: â€œUnits of data Spark processes independently.â€œ
ğŸ‘: Parallelism: â€œNumber of tasks that can run concurrently.â€œ
ğŸ‘: repartition(): â€œA wide transformation that reshuffles data to change partition count.â€œ






































