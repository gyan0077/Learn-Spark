# ======================== What is a View in Databricks?
A view is a saved query:
‚ùå Does not store data
‚úÖ Always reflects latest data


# ======================== Databricks 3 main types of views
üîπ 1Ô∏è‚É£ Temporary View (Session Scope)
It Exists only in the current Spark session and It automatically deleted when notebook / session ends.

-- When to use
i)   Intermediate transformations
ii)  ETL pipelines
iii) Debugging

-- How to create (PySpark)
df.createOrReplaceTempView("temp_movies")

-- How to query
spark.sql("SELECT * FROM temp_movies").show()

-- Key points
i)  Not visible in Catalog
ii) Not shared across notebooks
iii) Very fast


üîπ 2Ô∏è‚É£ Global Temporary View (Cluster Scope)
Shared across all notebooks, Exists as long as cluster is running.

-- When to use
i)  Share intermediate results across notebooks
ii) Team experiments

-- How to create (PySpark)
df.createOrReplaceGlobalTempView("global_movies")

-- How to query
spark.sql("SELECT * FROM global_temp.global_movies").show()

-- Key points
i)   Schema is always global_temp
ii)  Deleted when cluster stops
iii) Not stored permanently

üîπ 3Ô∏è‚É£ Permanent View (Catalog View) ‚úÖ (MOST IMPORTANT)
Stored in Unity Catalog
Persistent
Shared across users & notebooks

-- When to use
i)   Analytics
ii)  Reporting
iii) Production queries

-- How to create (SQL)
CREATE OR REPLACE VIEW workspace.default.marvel_movies_view AS
SELECT *
FROM workspace.default.movies
WHERE studio = 'Marvel Studios';

-- How to query
SELECT title, release_year
FROM workspace.default.marvel_movies_view;

-- Key points
i)   Appears in Catalog
ii)  Survives restarts
iii) Slightly slower than temp views

# =============================== View vs Table
| View             | Table                 |
| ---------------- | --------------------- |
| Stores query     | Stores data           |
| Lightweight      | Heavy                 |
| Auto-updates     | Static unless updated |
| Faster to create | Slower to create      |

==================== Reading the spark plans with explain() ==============================
-- .explain() is used to show how Spark plans to execute your query.

Logical Plan ‚Üí What you want to do (your query logic)
Physical Plan ‚Üí How Spark will actually do it (execution strategy)

Think of it like this üëá
üìù Logical plan = recipe
üç≥ Physical plan = cooking method

=================== Logical Plans
= Its types
i)   Parsed Logical Plan    - Spark understands the syntax
ii)  Analyzed Logical Plan  - Spark validates columns & tables
iii) Optimized Logical Plan - Optimized by Catalyst Optimizer 

=================== Physical Plan  (How Spark will actually execute it)
Which join strategy?
Will data shuffle?
Will Spark use Photon, Broadcast, SortMerge?
How many stages & tasks?

==========================
How Spark Converts Logical ‚Üí Physical
Code / SQL
   ‚Üì
Parsed Logical Plan
   ‚Üì
Analyzed Logical Plan
   ‚Üì
Optimized Logical Plan (Catalyst)
   ‚Üì
Physical Plan (Cost-based)
   ‚Üì
Execution on cluster


========Explanation: Spark first parses the query into a logical plan,
resolves tables and columns in the analyzed plan,
optimizes it using Catalyst rules,
and finally generates a physical plan that executes efficiently using Photon with predicate pushdown and column pruning.











