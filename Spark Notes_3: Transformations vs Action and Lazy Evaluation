============= 1Ô∏è‚É£ Transformations - (They build the plan)
Transformations define what you want to do to the data.
They do not execute immediately.

============= 2Ô∏è‚É£ Actions - (They trigger execution)
Actions ask Spark for a result.
When an action is called, Spark executes the whole DAG.

============= 3Ô∏è‚É£ Lazy Evaluation (Why Spark waits)
Lazy evaluation means Spark waits until an action before doing any work.
Note: Spark first records transformations, then optimizes, then executes once.

============= Real-life analogy üç≥ =============
Transformations = writing a recipe.
Action = turning on the stove.
Lazy evaluation = not cooking until someone orders food.

=============================== Spark Transformations (Lazy ‚Äì build the plan) =======================================
Transformations define what to do. They don‚Äôt execute immediately.

üî∏ Narrow Transformations: 
-- Each output partition depends on only ONE input partition (NO shuffle)

What spark does:
Partition 1 ‚Üí Partition 1
Partition 2 ‚Üí Partition 2
Partition 3 ‚Üí Partition 3

Data from one partition stays in the same partition.
| -----------------------|-------------------------------------------- |
| Transformation         | What it does                                |
| ---------------------- | ------------------------------------------- |
| `select()`             | Choose columns                              |
| `filter()` / `where()` | Filter rows                                 |
| `withColumn()`         | Add/modify column                           |
| `drop()`               | Remove column                               |
| `map()`                | Row-wise transform                          |
| `flatMap()`            | Map + flatten                               |
| `sample()`             | Sample rows                                 |
| `limit()`              | Limit rows                                  |



üî∏ Wide Transformations:
-- Each output partition depends on MULTIPLE input partitions (Shuffle happens)

What Spark does: 
Partition 1 ‚îÄ‚îê
Partition 2 ‚îÄ‚îº‚îÄ‚ñ∫ Shuffle ‚îÄ‚ñ∫ New Partitions
Partition 3 ‚îÄ‚îò

Data must move across partitions.
| Transformation         | What it does                        |
| ---------------------- | ----------------------------------- |
| `groupBy()`            | Group rows                          |
| `agg()`                | Aggregations                        |
| `join()`               | Combine DataFrames                  |
| `repartition()`        | Change partitions                   |
| `orderBy()` / `sort()` | Sort data                           |
| `cube()` / `rollup()`  | Multi-dim aggregations              |


üîπ Spark Actions (Eager ‚Äì trigger execution)
Actions trigger the execution of the entire DAG.
| Action          | Result               |
| --------------- | -------------------- |
| `show()`        | Display rows         |
| `count()`       | Row count            |
| `collect()`     | Bring data to driver |
| `take(n)`       | First `n` rows       |
| `first()`       | First row            |
| `foreach()`     | Apply function       |
| `write()`       | Save to storage      |
| `saveAsTable()` | Save as table        |
| `reduce()`      | Aggregate values     |


üîπ Transformations vs Actions (Quick Recall)
| Aspect       | Transformation | Action          |
| ------------ | -------------- | --------------- |
| Execution    | Lazy           | Immediate       |
| Builds DAG   | ‚úÖ              | ‚ùå            |
| Triggers job | ‚ùå              | ‚úÖ            |
| Output       | DataFrame      | Result / Output |


======================== Eager transaformation ==========================
Spark has NO eager transformations.
All Spark transformations are lazy.
Only actions are eager.

========================= What is Fault Tolerance in Spark? =========================
Fault tolerance means Spark can recover from failures (node, executor, task) without restarting the entire job or losing data.

üîπ Types of Failures Spark Handles
1Ô∏è‚É£ Executor failure (most common)
2Ô∏è‚É£ Task failure
3Ô∏è‚É£ Node failure
4Ô∏è‚É£ Data loss in memory
Spark handles all of these automatically.

üîπ How Spark Achieves Fault Tolerance (Key Concepts)
1Ô∏è‚É£ DAG Lineage (MOST IMPORTANT)
Spark does NOT replicate data like Hadoop. Instead, it remembers how data was created.
This is called lineage.

2Ô∏è‚É£ Task Re-execution:
If a task fails:Spark retries it automatically,Runs the same task on another executor.
Ex:
Executor 2 crashes
‚Üí Spark reruns the same task on Executor 5

3Ô∏è‚É£ Partition-Based Recovery:
Spark processes data in partitions.
If one partition is lost:
Only that partition is recomputed
Not the entire dataset
üìå This makes recovery fast and efficient.


=========================== üîë Golden Rule (Very Important)  ===========================
If you see Exchange in .explain() ‚Üí it is a WIDE transformation
No Exchange ‚Üí Narrow transformation.


































