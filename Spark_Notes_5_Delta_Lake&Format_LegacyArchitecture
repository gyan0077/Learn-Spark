========================= Delta Lake & Delta Format â€” Concepts  =========================
Delta Lake is an open storage layer that brings  ACID transactions Schema enforcement & time travel capablities to Data Lake.

ðŸ”¹ What is Delta Lake?
Delta Lake = Parquet files + transaction log + smart metadata

ðŸ”¹ What is Delta Format?
Delta format is how data is stored:
->  Actual data â†’ Parquet files
->  Metadata & history â†’ _delta_log/ directory

Delta Table
 â”œâ”€â”€ part-0000.parquet
 â”œâ”€â”€ part-0001.parquet
 â””â”€â”€ _delta_log/
      â”œâ”€â”€ 000000.json
      â”œâ”€â”€ 000001.json
      â””â”€â”€ ...

ðŸ”¹ Core Concepts of Delta Lake
1ï¸âƒ£ Transaction Log (_delta_log) â­ MOST IMPORTANT
-> Records every change to the table
-> Each commit creates a new version

Version 0 â†’ initial load 
Version 1 â†’ append
Version 2 â†’ update

2ï¸âƒ£ ACID Transactions
Delta Lake guarantees:
Atomicity   â€“ either all or nothing
Consistency â€“ before & after change should remain unchanged
Isolation   â€“ Transaction do not affect each other. (Multiple trx occur independently without interference)
Durability â€“  Commit data will save permanently.

3ï¸âƒ£ Time Travel â³
Query older versions of data.
Select * from workspace.default.company_stocks version as of 0 where Company =  'Apple'
Select * from workspace.default.company_stocks version as of 1 where Company =  'Apple'

or --> Python
spark.read.format("delta") \
  .option("versionAsOf", 5) \
  .table("sales")
--> Perfect for rollback & auditing.

ðŸŽ¯ Interview-Ready One-Liners â­
Delta Lake: â€œAn open storage layer that adds ACID transactions, schema enforcement, and time travel to data lakes.â€
Delta Format: â€œParquet files plus a transaction log that tracks all changes to a table.â€



====================== S3 bucket setup& external Catalog=========================
Step1: Create Amazon S3 bucket.
Goto Home page of S3->Click Create Bucket-->Give bucket name unique-->Acknodgle and Create Bucket. -->Uplod data.

upload doc

Step 2: Set-up a externla location.
Goto Catolog --> External data --> Create external Location --> AWS Quick Start --> Next(Give Bucket name)--> Generate New Token(Copy)-->Launch and quick start
(enter token)--Create Stack(Acknowledge)


Step3: Goto SQL Editor  and run below query.
Select * from csv.`s3://gp-company-stocks-001`
with (header = true,inferSchema = true)


-- Creating the Delta table
CREATE TABLE workspace.default.company_stocks
USING Delta
LOCATION 's3://gp-company-stocks-001/bronze/'
AS
SELECT
*,
current_timestamp as _ingested_at,
input_file_name() as _source_file,
uuid() as _bronze_id
From 
csv.`s3://gp-company-stocks-001/`
with (header = true,inferSchema = true);


-- To update few records and the chekc the version.
--update workspace.default.company_stocks set Stock_Price = 70 where Company = 'Apple'
  
--Select * from workspace.default.company_stocks version as of 0 where Company =  'Apple'
-- Select * from workspace.default.company_stocks version as of 1 where Company =  'Apple'

============================================= Intro To Tech Architecture ==================================
Once you GO thorough: project_ecommerce --> 1_setUp --> real_project (Code) the read below code for better understanding
======= Data Understanding & upload
Step: How to upload....
Once you ecommerce Catalog created ---> Click on it Create Schema(Schema Name 'Source Data') 
--> Click on (Schema which created 'Source Data') --> Click on Create Volume(Volume Name 'raw') 
--> Click on upload to this volume(Uplod all the folders)




============================================= Raw ====>  Bronze  ==================================
-- Transferring data from Raw to Bronze. and start working on Dimension Tables.
Step1: Under our project "project_ecommerce" we will create a one more folder "1_Medallion_Processing_Dim". 
and Under "1_Medallion_Processing_Dim" create a NoteBook "1_Dim_Bronze". 
Under this Notebook whatever dimention we have we will create a Table under bronze layer.and we are ingesting the data.
-- Check Code in "1_Dim_Bronze"



































